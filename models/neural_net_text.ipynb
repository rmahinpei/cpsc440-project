{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdpNfRiYmsQ"
      },
      "source": [
        "# **Neural Network for Text Classification**\n",
        "*   Implementation of a classic neural network for text classification supporting **multi-precision** training.\n",
        "    *   Implementation currently supports training in either double, single, or half precision.\n",
        "    *   This implies that both the computations and parameter storage are done in the specified precision.\n",
        "*   Implementation of a classic neural network for text classification supporting **mixed-precision** training.\n",
        "    *   Implementation currently supports half precision computations with single precision parameter storage.\n",
        "*   Implementations are based off of TensorFlow's very own example: [TensorFlow Text Classification Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta8jmKCVOASd"
      },
      "outputs": [],
      "source": [
        "import time, os, re, shutil, string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a global TF random seed\n",
        "tf.random.set_seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "az0Q5RPBOHA2"
      },
      "outputs": [],
      "source": [
        "# Define number of training runs to compute the average training time over\n",
        "NUM_TRAINING_RUNS = 2\n",
        "# Values are specific to the sentiment analysis dataset\n",
        "MAX_FEATURES = 10000\n",
        "EMBEDDING_DIM = 16\n",
        "SEQ_LENGTH = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GrSTETMTOJWx"
      },
      "outputs": [],
      "source": [
        "def build_and_train(train_ds, precision):\n",
        "    if precision == 'double':\n",
        "        dtype = tf.float64\n",
        "    elif precision == 'single':\n",
        "        dtype = tf.float32\n",
        "    else: # half\n",
        "        dtype = tf.float16\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(MAX_FEATURES, EMBEDDING_DIM, dtype=dtype),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.GlobalAveragePooling1D(dtype=dtype),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid', dtype=dtype)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zsxgiE_vqJZt"
      },
      "outputs": [],
      "source": [
        "def build_and_train_mixed(train_ds):\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(MAX_FEATURES, EMBEDDING_DIM),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    tf.keras.mixed_precision.set_global_policy('float32')\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H8Mz_BT1OMlJ"
      },
      "outputs": [],
      "source": [
        "# Load the sentiment analysis dataset\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate the training and test sets\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=12)\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the dataset for training\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=MAX_FEATURES,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQ_LENGTH)\n",
        "\n",
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Configure the dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test run to make sure that everything is working properly before starting actual measurements\n",
        "_ = build_and_train(train_ds, precision='single')\n",
        "_ = build_and_train_mixed(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hug4ZxznOXJl",
        "outputId": "b5c1534f-756e-4d0e-bf43-edc5a346d7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4985 - accuracy: 0.8257\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3679 - accuracy: 0.8683\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3337 - accuracy: 0.8787\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3120 - accuracy: 0.8855\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2935 - accuracy: 0.8909\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4995 - accuracy: 0.8242\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3722 - accuracy: 0.8661\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3352 - accuracy: 0.8777\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3127 - accuracy: 0.8857\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2948 - accuracy: 0.8911\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5007 - accuracy: 0.8243\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3797 - accuracy: 0.8642\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3401 - accuracy: 0.8763\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3166 - accuracy: 0.8832\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2963 - accuracy: 0.8904\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4930 - accuracy: 0.8271\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3754 - accuracy: 0.8660\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3358 - accuracy: 0.8782\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3116 - accuracy: 0.8857\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2949 - accuracy: 0.8911\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4982 - accuracy: 0.8248\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3748 - accuracy: 0.8657\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3356 - accuracy: 0.8777\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3123 - accuracy: 0.8868\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2927 - accuracy: 0.8925\n",
            "313/313 - 1s - loss: 0.3538 - accuracy: 0.8707 - 1s/epoch - 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with double precision\n",
        "time_double = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_double, training_time = build_and_train(train_ds, 'double')\n",
        "    time_double += training_time\n",
        "accuracy_double = model_double.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeiaRBnrOXpM",
        "outputId": "39c71db4-def1-4895-81e3-19850a9ee6e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5019 - accuracy: 0.8230\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3754 - accuracy: 0.8645\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3379 - accuracy: 0.8782\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3146 - accuracy: 0.8837\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.8908\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4996 - accuracy: 0.8235\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8647\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3345 - accuracy: 0.8784\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3136 - accuracy: 0.8854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2949 - accuracy: 0.8913\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4931 - accuracy: 0.8273\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3740 - accuracy: 0.8651\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8784\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3102 - accuracy: 0.8842\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2911 - accuracy: 0.8926\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4965 - accuracy: 0.8263\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3716 - accuracy: 0.8656\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3341 - accuracy: 0.8781\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3092 - accuracy: 0.8876\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.8908\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4958 - accuracy: 0.8266\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3747 - accuracy: 0.8650\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3135 - accuracy: 0.8860\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.8909\n",
            "313/313 - 1s - loss: 0.3536 - accuracy: 0.8739 - 633ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with single precision\n",
        "time_single = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_single, training_time = build_and_train(train_ds, 'single')\n",
        "    time_single += training_time\n",
        "accuracy_single = model_single.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JwOnOspOZ8M",
        "outputId": "1fb49ae2-1347-48fb-80b8-b6bb1c72fb34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 2ms/step - loss: 19.0189 - accuracy: 0.6873\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.4242 - accuracy: 0.7836\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.6212 - accuracy: 0.7988\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.1600 - accuracy: 0.8119\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9285 - accuracy: 0.8164\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 17.7464 - accuracy: 0.6802\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.6308 - accuracy: 0.7764\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.4356 - accuracy: 0.7973\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9762 - accuracy: 0.8085\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.6820 - accuracy: 0.8156\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 17.6363 - accuracy: 0.6987\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.0112 - accuracy: 0.7775\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.8103 - accuracy: 0.7973\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.1254 - accuracy: 0.8088\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7790 - accuracy: 0.8150\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 26.0007 - accuracy: 0.6519\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.6736 - accuracy: 0.7671\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 4.0370 - accuracy: 0.7891\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.0737 - accuracy: 0.7998\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.4697 - accuracy: 0.8100\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 16.3988 - accuracy: 0.6734\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 3.9535 - accuracy: 0.7793\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.8615 - accuracy: 0.7985\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3178 - accuracy: 0.8092\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9773 - accuracy: 0.8180\n",
            "313/313 - 1s - loss: 2.1564 - accuracy: 0.8021 - 647ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with half precision\n",
        "time_half = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_half, training_time = build_and_train(train_ds, 'half')\n",
        "    time_half += training_time\n",
        "accuracy_half = model_half.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXjfm8QUtwwl",
        "outputId": "7951f1e4-e2be-4f41-f106-c74aaa0fef03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5001 - accuracy: 0.8242\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3740 - accuracy: 0.8640\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3387 - accuracy: 0.8760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3143 - accuracy: 0.8853\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2941 - accuracy: 0.8918\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4932 - accuracy: 0.8255\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3743 - accuracy: 0.8645\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3359 - accuracy: 0.8767\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3124 - accuracy: 0.8854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2935 - accuracy: 0.8908\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4988 - accuracy: 0.8235\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3769 - accuracy: 0.8648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3378 - accuracy: 0.8773\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3146 - accuracy: 0.8856\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2957 - accuracy: 0.8904\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4927 - accuracy: 0.8267\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3712 - accuracy: 0.8656\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3341 - accuracy: 0.8772\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3097 - accuracy: 0.8860\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2920 - accuracy: 0.8922\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4924 - accuracy: 0.8265\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3732 - accuracy: 0.8652\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3326 - accuracy: 0.8795\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3075 - accuracy: 0.8870\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2920 - accuracy: 0.8916\n",
            "313/313 - 1s - loss: 0.3452 - accuracy: 0.8776 - 660ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with mixed half precision\n",
        "time_mixed = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_mixed, training_time = build_and_train_mixed(train_ds)\n",
        "    time_mixed += training_time\n",
        "accuracy_mixed = model_mixed.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHPKe0o2Q-Vb",
        "outputId": "a8e9b505-e4d5-4675-ec4f-e451d5a304b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---RESULTS---\n",
            "Average training time in double precision: 41.96263284683228 seconds\n",
            "Average training time in single precision: 38.48553071022034 seconds\n",
            "Average training time in half precision: 35.364750146865845 seconds\n",
            "Average training time in mixed half precision: 37.08986630439758 seconds\n",
            "-------------\n",
            "Accuracy with double precision: 0.8707000017166138\n",
            "Accuracy with single precision: 0.8738999962806702\n",
            "Accuracy with half precision: 0.8738999962806702\n",
            "Accuracy with mixed half precision: 0.8776000142097473\n"
          ]
        }
      ],
      "source": [
        "print(\"---RESULTS---\")\n",
        "print(\"Average training time in double precision:\", time_double / NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in single precision:\", time_single/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in half precision:\", time_half/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in mixed half precision:\", time_mixed/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"-------------\")\n",
        "print(\"Accuracy with double precision:\", accuracy_double)\n",
        "print(\"Accuracy with single precision:\", accuracy_single)\n",
        "print(\"Accuracy with half precision:\", accuracy_single)\n",
        "print(\"Accuracy with mixed half precision:\", accuracy_mixed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
