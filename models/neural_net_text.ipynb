{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdpNfRiYmsQ"
      },
      "source": [
        "# **Neural Network for Text Classification**\n",
        "*   Implementation of a classic neural network for text classification supporting **multi-precision** training.\n",
        "    *   Implementation currently supports training in either double, single, or half precision.\n",
        "    *   This implies that both the computations and parameter storage are done in the specified precision.\n",
        "*   Implementation of a classic neural network for text classification supporting **mixed-precision** training.\n",
        "    *   Implementation currently supports half precision computations with single precision parameter storage.\n",
        "*   Implementations are based off of TensorFlow's very own example: [TensorFlow Text Classification Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ta8jmKCVOASd"
      },
      "outputs": [],
      "source": [
        "import time, os, re, shutil, string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_CEuWyqdv9jE"
      },
      "outputs": [],
      "source": [
        "# Set a global random seed\n",
        "tf.random.set_seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "az0Q5RPBOHA2"
      },
      "outputs": [],
      "source": [
        "# Define number of training runs to compute the average training time over\n",
        "NUM_TRAINING_RUNS = 2\n",
        "# Values are specific to the sentiment analysis dataset\n",
        "MAX_FEATURES = 10000\n",
        "EMBEDDING_DIM = 16\n",
        "SEQ_LENGTH = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GrSTETMTOJWx"
      },
      "outputs": [],
      "source": [
        "def build_and_train(train_ds, precision):\n",
        "    if precision == 'double':\n",
        "        dtype = tf.float64\n",
        "    elif precision == 'single':\n",
        "        dtype = tf.float32\n",
        "    else: # half\n",
        "        dtype = tf.float16\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(MAX_FEATURES, EMBEDDING_DIM, dtype=dtype),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.GlobalAveragePooling1D(dtype=dtype),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid', dtype=dtype)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zsxgiE_vqJZt"
      },
      "outputs": [],
      "source": [
        "def build_and_train_mixed(train_ds):\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(MAX_FEATURES, EMBEDDING_DIM),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    tf.keras.mixed_precision.set_global_policy('float32')\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H8Mz_BT1OMlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88fd825-b0ea-4e0f-d59c-092c062a0aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the sentiment analysis dataset\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCgxa-qav9jF",
        "outputId": "925617fb-762a-469a-f6bb-212866f9ec3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Separate the training and test sets\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=12)\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tuW0P-wfv9jG"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset for training\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=MAX_FEATURES,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQ_LENGTH)\n",
        "\n",
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Configure the dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovA4kHm2v9jG",
        "outputId": "b755f8b2-73c6-48c9-b507-cbe2f9279e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 53s 79ms/step - loss: 0.6634 - accuracy: 0.6876\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5492 - accuracy: 0.8025\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.4440 - accuracy: 0.8463\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3775 - accuracy: 0.8650\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3341 - accuracy: 0.8787\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 31s 48ms/step - loss: 0.6662 - accuracy: 0.6768\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5523 - accuracy: 0.7997\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4460 - accuracy: 0.8442\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3789 - accuracy: 0.8645\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3354 - accuracy: 0.8786\n"
          ]
        }
      ],
      "source": [
        "# Test run to make sure that everything is working properly before starting actual measurements\n",
        "_ = build_and_train(train_ds, precision='single')\n",
        "_ = build_and_train_mixed(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hug4ZxznOXJl",
        "outputId": "be6cd8b3-d8d9-4214-ef4d-5d8f6360c447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 58s 89ms/step - loss: 0.6616 - accuracy: 0.6847\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5448 - accuracy: 0.8052\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4408 - accuracy: 0.8462\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3754 - accuracy: 0.8663\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3327 - accuracy: 0.8800\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.6643 - accuracy: 0.6832\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5509 - accuracy: 0.8001\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4456 - accuracy: 0.8450\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3787 - accuracy: 0.8655\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3352 - accuracy: 0.8785\n",
            "157/157 - 1s - loss: 0.3492 - accuracy: 0.8630 - 675ms/epoch - 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with double precision\n",
        "time_double = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_double, training_time = build_and_train(train_ds, 'double')\n",
        "    time_double += training_time\n",
        "accuracy_double = model_double.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeiaRBnrOXpM",
        "outputId": "96dba93e-beae-4c32-916a-6ee819e805d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.6663 - accuracy: 0.6734\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5510 - accuracy: 0.7999\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4446 - accuracy: 0.8452\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3781 - accuracy: 0.8648\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3349 - accuracy: 0.8782\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 0.6644 - accuracy: 0.6847\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5496 - accuracy: 0.8008\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4439 - accuracy: 0.8452\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3775 - accuracy: 0.8648\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3342 - accuracy: 0.8789\n",
            "157/157 - 0s - loss: 0.3487 - accuracy: 0.8630 - 358ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with single precision\n",
        "time_single = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_single, training_time = build_and_train(train_ds, 'single')\n",
        "    time_single += training_time\n",
        "accuracy_single = model_single.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JwOnOspOZ8M",
        "outputId": "27bbcab2-fd95-4f42-879b-e9afbec20cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 52s 80ms/step - loss: 0.6057 - accuracy: 0.6881\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5178 - accuracy: 0.7503\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4748 - accuracy: 0.7763\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4520 - accuracy: 0.7911\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4392 - accuracy: 0.7974\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 32s 50ms/step - loss: 0.6225 - accuracy: 0.7218\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5188 - accuracy: 0.7799\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4255 - accuracy: 0.8128\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3931 - accuracy: 0.8220\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3824 - accuracy: 0.8293\n",
            "157/157 - 0s - loss: 0.3777 - accuracy: 0.8336 - 361ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with half precision\n",
        "time_half = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_half, training_time = build_and_train(train_ds, 'half')\n",
        "    time_half += training_time\n",
        "accuracy_half = model_half.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXjfm8QUtwwl",
        "outputId": "39c9868e-1936-4804-e2b7-b29353f74560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 31s 48ms/step - loss: 0.6654 - accuracy: 0.6801\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5508 - accuracy: 0.7994\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4452 - accuracy: 0.8442\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3785 - accuracy: 0.8647\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3354 - accuracy: 0.8783\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 31s 47ms/step - loss: 0.6630 - accuracy: 0.6827\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5458 - accuracy: 0.8030\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4409 - accuracy: 0.8464\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3754 - accuracy: 0.8662\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3328 - accuracy: 0.8792\n",
            "157/157 - 0s - loss: 0.3478 - accuracy: 0.8624 - 338ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with mixed half precision\n",
        "time_mixed = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_mixed, training_time = build_and_train_mixed(train_ds)\n",
        "    time_mixed += training_time\n",
        "accuracy_mixed = model_mixed.evaluate(test_ds, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHPKe0o2Q-Vb",
        "outputId": "c18fdbb0-3735-44ad-dc3f-9541785d1891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RESULTS---\n",
            "Average training time in double precision: 68.55340373516083 seconds\n",
            "Average training time in single precision: 39.94835674762726 seconds\n",
            "Average training time in half precision: 61.70956468582153 seconds\n",
            "Average training time in mixed half precision: 42.24100053310394 seconds\n",
            "-------------\n",
            "Accuracy with double precision: 0.8629999756813049\n",
            "Accuracy with single precision: 0.8629999756813049\n",
            "Accuracy with half precision: 0.8335999846458435\n",
            "Accuracy with mixed half precision: 0.8623999953269958\n"
          ]
        }
      ],
      "source": [
        "print(\"---RESULTS---\")\n",
        "print(\"Average training time in double precision:\", time_double / NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in single precision:\", time_single/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in half precision:\", time_half/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in mixed half precision:\", time_mixed/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"-------------\")\n",
        "print(\"Accuracy with double precision:\", accuracy_double)\n",
        "print(\"Accuracy with single precision:\", accuracy_single)\n",
        "print(\"Accuracy with half precision:\", accuracy_half)\n",
        "print(\"Accuracy with mixed half precision:\", accuracy_mixed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}