{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdpNfRiYmsQ"
      },
      "source": [
        "# **Neural Network for Text Classification**\n",
        "*   Implementation of a classic neural network for text classification supporting **multi-precision** training.\n",
        "    *   Implementation currently supports training in either double, single, or half precision.\n",
        "    *   This implies that both the computations and parameter storage are done in the specified precision.\n",
        "*   Implementation of a classic neural network for text classification supporting **mixed-precision** training.\n",
        "    *   Implementation currently supports half precision computations with single precision parameter storage.\n",
        "*   Implementations are based off of TensorFlow's very own example: [TensorFlow Text Classification Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ta8jmKCVOASd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_CEuWyqdv9jE"
      },
      "outputs": [],
      "source": [
        "tfds.disable_progress_bar()\n",
        "# Set a global random seed\n",
        "tf.random.set_seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "az0Q5RPBOHA2"
      },
      "outputs": [],
      "source": [
        "# Define number of training runs to compute the average training time over\n",
        "NUM_TRAINING_RUNS = 3\n",
        "# Values are specific to the sentiment analysis dataset\n",
        "VOCAB_SIZE = 1000\n",
        "EMBEDDING_DIM = 64\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GrSTETMTOJWx"
      },
      "outputs": [],
      "source": [
        "def build_and_train(train_ds, encoder, precision):\n",
        "    if precision == 'double':\n",
        "        dtype = tf.float64\n",
        "    elif precision == 'single':\n",
        "        dtype = tf.float32\n",
        "    else: # half\n",
        "        dtype = tf.float16\n",
        "\n",
        "    model = models.Sequential([\n",
        "        encoder,\n",
        "        layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, dtype=dtype),\n",
        "        layers.Dropout(0.2, dtype=dtype), # !!!\n",
        "        layers.GlobalAveragePooling1D(dtype=dtype),\n",
        "        layers.Dropout(0.2, dtype=dtype), # !!!\n",
        "        layers.Dense(1, activation='sigmoid', dtype=dtype)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zsxgiE_vqJZt"
      },
      "outputs": [],
      "source": [
        "def build_and_train_mixed(train_ds, encoder):\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "    model = models.Sequential([\n",
        "        encoder,\n",
        "        layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ds, epochs=5)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    tf.keras.mixed_precision.set_global_policy('float32')\n",
        "    return model, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Mz_BT1OMlJ",
        "outputId": "3fbf6580-fd3f-415c-97c6-00b6b6b08a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "# Load dataset and split into train and test sets\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JCgxa-qav9jF"
      },
      "outputs": [],
      "source": [
        "# Create the text encoder\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovA4kHm2v9jG",
        "outputId": "97c2e48b-af53-4431-85cb-bd91dc205de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 19s 42ms/step - loss: 0.6824 - accuracy: 0.5886\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.6280 - accuracy: 0.7195\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.5577 - accuracy: 0.7754\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4976 - accuracy: 0.8081\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.4508 - accuracy: 0.8290\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 15s 31ms/step - loss: 0.6821 - accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6289 - accuracy: 0.7242\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.5566 - accuracy: 0.7762\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4946 - accuracy: 0.8118\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.4509 - accuracy: 0.8301\n"
          ]
        }
      ],
      "source": [
        "# Test run to make sure that everything is working properly before starting actual measurements\n",
        "_ = build_and_train(train_dataset, encoder, precision='single')\n",
        "_ = build_and_train_mixed(train_dataset, encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hug4ZxznOXJl",
        "outputId": "3203e798-294e-4961-9e16-a69595eefdf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 27s 59ms/step - loss: 0.6827 - accuracy: 0.5941\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.6288 - accuracy: 0.7156\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.5572 - accuracy: 0.7722\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.4967 - accuracy: 0.8108\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.4517 - accuracy: 0.8281\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 22s 53ms/step - loss: 0.6826 - accuracy: 0.5986\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.6313 - accuracy: 0.7231\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.5605 - accuracy: 0.7711\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.4991 - accuracy: 0.8077\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.4536 - accuracy: 0.8270\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 21s 49ms/step - loss: 0.6823 - accuracy: 0.5988\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6284 - accuracy: 0.7192\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5562 - accuracy: 0.7766\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.4947 - accuracy: 0.8124\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.4490 - accuracy: 0.8289\n",
            "391/391 - 4s - loss: 0.4323 - accuracy: 0.8342 - 4s/epoch - 10ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with double precision\n",
        "time_double = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_double, training_time = build_and_train(train_dataset, encoder, 'double')\n",
        "    time_double += training_time\n",
        "accuracy_double = model_double.evaluate(test_dataset, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeiaRBnrOXpM",
        "outputId": "da8b0261-6bf8-4ee9-cc8b-ed7003c17eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 13s 30ms/step - loss: 0.6827 - accuracy: 0.5978\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6294 - accuracy: 0.7156\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5562 - accuracy: 0.7765\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4981 - accuracy: 0.8079\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4508 - accuracy: 0.8268\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 12s 27ms/step - loss: 0.6824 - accuracy: 0.6043\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.6287 - accuracy: 0.7087\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5557 - accuracy: 0.7784\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4939 - accuracy: 0.8084\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4486 - accuracy: 0.8284\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 12s 28ms/step - loss: 0.6823 - accuracy: 0.6049\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6278 - accuracy: 0.7190\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5553 - accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4953 - accuracy: 0.8093\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.4504 - accuracy: 0.8270\n",
            "391/391 - 2s - loss: 0.4345 - accuracy: 0.8342 - 2s/epoch - 6ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with single precision\n",
        "time_single = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_single, training_time = build_and_train(train_dataset, encoder, 'single')\n",
        "    time_single += training_time\n",
        "accuracy_single = model_single.evaluate(test_dataset, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JwOnOspOZ8M",
        "outputId": "4579bd09-c6d5-414d-f722-a33b81ba92e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 55s 139ms/step - loss: 0.6659 - accuracy: 0.6795\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.5616 - accuracy: 0.7579\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.5504 - accuracy: 0.7755\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.5119 - accuracy: 0.7929\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 38s 97ms/step - loss: 0.4980 - accuracy: 0.7986\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 50s 125ms/step - loss: 0.7468 - accuracy: 0.6613\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.6273 - accuracy: 0.7326\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.6010 - accuracy: 0.7509\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 37s 95ms/step - loss: 0.6253 - accuracy: 0.7626\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.5401 - accuracy: 0.7818\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 55s 138ms/step - loss: 0.7630 - accuracy: 0.5999\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 50s 126ms/step - loss: 0.6608 - accuracy: 0.6743\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.5987 - accuracy: 0.7078\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.5828 - accuracy: 0.7221\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 51s 129ms/step - loss: 0.5385 - accuracy: 0.7410\n",
            "391/391 - 2s - loss: 0.4848 - accuracy: 0.7747 - 2s/epoch - 6ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with half precision\n",
        "time_half = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_half, training_time = build_and_train(train_dataset, encoder, 'half')\n",
        "    time_half += training_time\n",
        "accuracy_half = model_half.evaluate(test_dataset, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXjfm8QUtwwl",
        "outputId": "fb005d42-0587-4b15-a928-b186081d339d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 13s 29ms/step - loss: 0.6831 - accuracy: 0.5934\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6287 - accuracy: 0.7136\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5554 - accuracy: 0.7757\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 5s 11ms/step - loss: 0.4941 - accuracy: 0.8097\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 11ms/step - loss: 0.4487 - accuracy: 0.8304\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 13s 30ms/step - loss: 0.6825 - accuracy: 0.5856\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6265 - accuracy: 0.7200\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.5535 - accuracy: 0.7760\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4935 - accuracy: 0.8111\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.4485 - accuracy: 0.8290\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 13s 30ms/step - loss: 0.6825 - accuracy: 0.5874\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6336 - accuracy: 0.7034\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.5650 - accuracy: 0.7692\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5045 - accuracy: 0.8054\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 5s 11ms/step - loss: 0.4575 - accuracy: 0.8252\n",
            "391/391 - 2s - loss: 0.4391 - accuracy: 0.8330 - 2s/epoch - 6ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train with mixed half precision\n",
        "time_mixed = 0.0\n",
        "for _ in range(NUM_TRAINING_RUNS):\n",
        "    model_mixed, training_time = build_and_train_mixed(train_dataset, encoder)\n",
        "    time_mixed += training_time\n",
        "accuracy_mixed = model_mixed.evaluate(test_dataset, verbose=2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHPKe0o2Q-Vb",
        "outputId": "99d1eb82-aef9-4433-c534-b7dc97f52f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---RESULTS---\n",
            "Average training time in double precision: 63.01487056414286 seconds\n",
            "Average training time in single precision: 31.267759720484417 seconds\n",
            "Average training time in half precision: 270.6589232285817 seconds\n",
            "Average training time in mixed half precision: 42.05624405543009 seconds\n",
            "-------------\n",
            "Accuracy with double precision: 0.8341599702835083\n",
            "Accuracy with single precision: 0.8341599702835083\n",
            "Accuracy with half precision: 0.7747200131416321\n",
            "Accuracy with mixed half precision: 0.8330399990081787\n"
          ]
        }
      ],
      "source": [
        "print(\"---RESULTS---\")\n",
        "print(\"Average training time in double precision:\", time_double / NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in single precision:\", time_single/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in half precision:\", time_half/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"Average training time in mixed half precision:\", time_mixed/ NUM_TRAINING_RUNS, \"seconds\")\n",
        "print(\"-------------\")\n",
        "print(\"Accuracy with double precision:\", accuracy_double)\n",
        "print(\"Accuracy with single precision:\", accuracy_single)\n",
        "print(\"Accuracy with half precision:\", accuracy_half)\n",
        "print(\"Accuracy with mixed half precision:\", accuracy_mixed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
